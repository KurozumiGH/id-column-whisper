{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec20fd79-6c0a-4cda-904f-485165d62b50",
   "metadata": {},
   "source": [
    "# Whisper\n",
    "\n",
    "https://github.com/openai/whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471f944-6d60-4023-b87f-51bcbe92c386",
   "metadata": {},
   "source": [
    "## 環境情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3df69b-4e98-4c49-8e1e-044506b6e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831a5bae-6baf-4108-9fa5-b82ad5a284a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 13 00:14:59 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.75       Driver Version: 517.40       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   34C    P8    32W / 280W |   3666MiB / 24576MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861423d-92a2-4682-9467-3aa85bd7952c",
   "metadata": {},
   "source": [
    "## 簡易的な操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fbce57-f724-4e0f-95dc-1653a489cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "# デフォルトのキャッシュフォルダを環境変数で指定\n",
    "os.environ[\"XDG_CACHE_HOME\"] = \"./.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380ba549-ac44-4c1e-8af7-8f1a17371130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのロード\n",
    "model = whisper.load_model(\"medium\")\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ca72d3-dbe5-45af-9c86-1232640521ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おはようございますおはようございますそれでは早速、今週の定例ミーティングを始めたいと思いますまずは山田さん、先週の調査結果について報告していただけますか?はい、山田です。少々お待ちくださいえっと、先週発生していた不具合の件ですが、一通り調査した結果入力されたデータに誤りがあったことが分かりましたなので、プログラムとかに問題はありませんでしたあ、佐々木です。その件で少し補足します入力データの間違いですが、このままだとまた同じ間違いが出てくると思います間違っても大丈夫なように、プログラムでエラーチェックをするようにした方が良いと思います確かにそうですよね。私もそうした方が良いと思います報告ありがとうございます。では、この件については次の開発計画に取り込むように調整しておきますね\n",
      "CPU times: user 27.1 s, sys: 2.7 s, total: 29.8 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 音声ファイルの解析\n",
    "result = model.transcribe(\"./data/sample.flac\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51aebbed-a569-4a39-b46b-44a929e3c661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japanese'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 言語判定\n",
    "whisper.tokenizer.LANGUAGES[result[\"language\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a5eb95-026b-444c-afe7-af44cb57cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000:   0.0 -   1.2 | おはようございます\n",
      "001:   1.2 -   3.2 | おはようございます\n",
      "002:   3.2 -   8.5 | それでは早速、今週の定例ミーティングを始めたいと思います\n",
      "003:   8.5 -  14.0 | まずは山田さん、先週の調査結果について報告していただけますか?\n",
      "004:  14.0 -  18.8 | はい、山田です。少々お待ちください\n",
      "005:  18.8 -  24.3 | えっと、先週発生していた不具合の件ですが、一通り調査した結果\n",
      "006:  24.3 -  27.9 | 入力されたデータに誤りがあったことが分かりました\n",
      "007:  27.9 -  31.3 | なので、プログラムとかに問題はありませんでした\n",
      "008:  31.3 -  36.3 | あ、佐々木です。その件で少し補足します\n",
      "009:  36.3 -  42.3 | 入力データの間違いですが、このままだとまた同じ間違いが出てくると思います\n",
      "010:  42.3 -  48.9 | 間違っても大丈夫なように、プログラムでエラーチェックをするようにした方が良いと思います\n",
      "011:  48.9 -  54.0 | 確かにそうですよね。私もそうした方が良いと思います\n",
      "012:  54.0 -  63.5 | 報告ありがとうございます。では、この件については次の開発計画に取り込むように調整しておきますね\n"
     ]
    }
   ],
   "source": [
    "# セグメントごとに表示\n",
    "for seg in result[\"segments\"]:\n",
    "    id, start, end, text = [seg[key] for key in [\"id\", \"start\", \"end\", \"text\"]]\n",
    "    print(f\"{id:03}: {start:5.1f} - {end:5.1f} | {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75428e5c-61ff-4336-bf3a-6fec68b60ffb",
   "metadata": {},
   "source": [
    "## 英語翻訳書き起こし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c629c52d-5641-4058-b234-5bfe497b99ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Good morning. Good morning. Now, let's start this week's regular meeting. First, Mr. Yamada, can you tell us about the results of the last week's investigation? Yes, I'm Yamada. Please wait a moment. Well, about the unforeseen events that occurred last week, we found that there was an error in the data that was entered as a result of the investigation. So there was no problem with the program. Oh, Sasaki. I'll make a little correction on that. It's a mistake in the input data, but I think that if it continues like this, we'll have the same mistake again. I think it's better to check the error in the program as if it's okay if you make a mistake. That's true. I think it's better to do that too. Thank you for your report. Well, I'll adjust this to be included in the next development plan.\n"
     ]
    }
   ],
   "source": [
    "# 翻訳\n",
    "result = model.transcribe(\"./data/sample.flac\", task=\"translate\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bed742-c5d9-416c-9348-d80ead81a47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000|   0.0 -   1.1 |  Good morning.\n",
      "001|   1.1 -   2.8 |  Good morning.\n",
      "002|   3.2 -   7.5 |  Now, let's start this week's regular meeting.\n",
      "003|   8.4 -  13.1 |  First, Mr. Yamada, can you tell us about the results of the last week's investigation?\n",
      "004|  14.0 -  17.0 |  Yes, I'm Yamada. Please wait a moment.\n",
      "005|  18.8 -  22.0 |  Well, about the unforeseen events that occurred last week,\n",
      "006|  22.4 -  27.1 |  we found that there was an error in the data that was entered as a result of the investigation.\n",
      "007|  27.1 -  30.4 |  So there was no problem with the program.\n",
      "008|  30.4 -  34.9 |  Oh, Sasaki. I'll make a little correction on that.\n",
      "009|  35.5 -  39.2 |  It's a mistake in the input data, but I think that if it continues like this,\n",
      "010|  39.2 -  41.4 |  we'll have the same mistake again.\n",
      "011|  41.4 -  47.2 |  I think it's better to check the error in the program as if it's okay if you make a mistake.\n",
      "012|  48.2 -  52.0 |  That's true. I think it's better to do that too.\n",
      "013|  53.2 -  55.1 |  Thank you for your report.\n",
      "014|  55.1 -  61.1 |  Well, I'll adjust this to be included in the next development plan.\n"
     ]
    }
   ],
   "source": [
    "# セグメントごとに表示\n",
    "for segment in result[\"segments\"]:\n",
    "    id, start, end, text = [segment[key] for key in [\"id\", \"start\", \"end\", \"text\"]]\n",
    "    print(f\"{id:03}| {start:5.1f} - {end:5.1f} | {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7fd58-f2c7-45dc-8dc0-00a18935d9e0",
   "metadata": {},
   "source": [
    "## 感情分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468cd9c0-6657-4524-82c1-5d1ff5353901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000|   0.0 -   1.2 | ポジ 0.99 | おはようございます\n",
      "001|   1.2 -   3.2 | ポジ 0.99 | おはようございます\n",
      "002|   3.2 -   8.5 | ポジ 0.96 | それでは早速、今週の定例ミーティングを始めたいと思います\n",
      "003|   8.5 -  14.0 | ポジ 0.95 | まずは山田さん、先週の調査結果について報告していただけますか?\n",
      "004|  14.0 -  18.8 | ポジ 0.98 | はい、山田です。少々お待ちください\n",
      "005|  18.8 -  24.3 | ポジ 0.69 | えっと、先週発生していた不具合の件ですが、一通り調査した結果\n",
      "006|  24.3 -  27.9 | ネガ 0.56 | 入力されたデータに誤りがあったことが分かりました\n",
      "007|  27.9 -  31.3 | ポジ 0.92 | なので、プログラムとかに問題はありませんでした\n",
      "008|  31.3 -  36.3 | ポジ 0.95 | あ、佐々木です。その件で少し補足します\n",
      "009|  36.3 -  42.3 | ネガ 0.78 | 入力データの間違いですが、このままだとまた同じ間違いが出てくると思います\n",
      "010|  42.3 -  48.9 | ポジ 0.96 | 間違っても大丈夫なように、プログラムでエラーチェックをするようにした方が良いと思います\n",
      "011|  48.9 -  54.0 | ポジ 0.96 | 確かにそうですよね。私もそうした方が良いと思います\n",
      "012|  54.0 -  63.5 | ポジ 0.87 | 報告ありがとうございます。では、この件については次の開発計画に取り込むように調整しておきますね\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from transformers import pipeline\n",
    "\n",
    "# 音声から文字の書き起こし\n",
    "whisper_model = whisper.load_model(\"medium\")\n",
    "segments = whisper_model.transcribe(\"./data/sample.flac\")[\"segments\"]\n",
    "segments_text = [seg[\"text\"] for seg in segments]  # textだけをリストで抽出\n",
    "\n",
    "# 書き起こした文章の感情分析\n",
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"daigo/bert-base-japanese-sentiment\",\n",
    "    tokenizer=\"daigo/bert-base-japanese-sentiment\",\n",
    ")\n",
    "sentiments = sentiment_model(segments_text)\n",
    "\n",
    "# 文字起こしした内容と感情分析結果を結合して結果表示\n",
    "for segment, sentiment in zip(segments, sentiments):\n",
    "    id, start, end, text = [segment[key] for key in [\"id\", \"start\", \"end\", \"text\"]]\n",
    "    label, score = [sentiment[key] for key in [\"label\", \"score\"]]\n",
    "\n",
    "    print(f\"{id:03}| {start:5.1f} - {end:5.1f} | {label[:2]} {score:4.2f} | {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
